# ğŸ§  Text Classification using Transformers (PyTorch & TensorFlow)

## ğŸ“Œ Overview

This project builds a **text classification system** to categorize real-world message data into one of three categories:

* **Enquiry**
* **Job**
* **Spam**

It starts with a **TF-IDF + Neural Network** (PyTorch), then progresses to an advanced version using **Transformers (BERT)** with **both PyTorch and TensorFlow**. This covers foundational to modern NLP approaches in a semi-supervised learning setting.

---

## ğŸ“‚ Dataset

* **Source**: Real-world business message dataset (`contacts_message.csv`)
* **Columns**:

  * `message`: Raw user message
  * `label`: Manually annotated label (only \~105 out of \~1700 are labeled)
* This is a **semi-supervised** use case (limited labeled data).

---

## ğŸš€ Features

âœ… Text vectorization using **TF-IDF**
âœ… Simple neural network with **PyTorch**
âœ… Transformer-based classifier using **BERT (HuggingFace Transformers)**
âœ… Implemented in both **PyTorch** and **TensorFlow**
âœ… Label encoding & decoding
âœ… Single message prediction interface
âœ… Model evaluation & accuracy report

---

## ğŸ› ï¸ Requirements

```bash
pip install torch transformers tensorflow scikit-learn pandas numpy
```

---

## ğŸ“ Project Structure

```
text-classifier/
â”œâ”€â”€ foduu_contacts_message.csv       # Input CSV with messages
â”œâ”€â”€ train.py                         # PyTorch model training with TF-IDF
â”œâ”€â”€ predict.py                       # PyTorch TF-IDF-based prediction
â”œâ”€â”€ bert_pytorch.py                  # BERT-based model using PyTorch
â”œâ”€â”€ bert_tensorflow.py               # BERT-based model using TensorFlow
â”œâ”€â”€ model.pth                        # Saved PyTorch model
â”œâ”€â”€ bert_model.h5                    # Saved TensorFlow BERT model
â”œâ”€â”€ vectorizer.pkl                   # TF-IDF vectorizer (pickle)
â”œâ”€â”€ label_encoder.pkl                # Label encoder (pickle)
â””â”€â”€ README.md                        # Project documentation
```

---

## âš™ï¸ How to Use

### 1ï¸âƒ£ Train Basic Model (TF-IDF + NN)

```bash
python train.py
```

This:

* Loads labeled data
* Vectorizes using TF-IDF
* Trains a feedforward NN
* Saves model, vectorizer, and label encoder

### 2ï¸âƒ£ Predict with Basic Model

```python
from predict import predict_message
print(predict_message("Looking for freelance job"))  # â¡ï¸ job
```

### 3ï¸âƒ£ Train BERT Model (PyTorch)

```bash
python bert_pytorch.py
```

Trains a Transformer-based classifier using HuggingFace and PyTorch.

### 4ï¸âƒ£ Train BERT Model (TensorFlow)

```bash
python bert_tensorflow.py
```

Runs the same logic in TensorFlow (using Keras Functional API + BERT).

---

## ğŸ§  Model Architectures

### TF-IDF + Feedforward NN

* **Input**: TF-IDF (500 features)
* **Hidden**: 128 neurons, ReLU
* **Output**: 3 classes (softmax)
* **Loss**: CrossEntropyLoss
* **Optimizer**: Adam
* **Framework**: PyTorch

### Transformer (BERT)

* **Input**: Tokenized message
* **Base**: `bert-base-uncased` (HuggingFace)
* **Output**: Softmax layer (3 classes)
* **Loss**: CrossEntropy
* **Frameworks**: PyTorch & TensorFlow

---

## ğŸ“Š Evaluation

* Accuracy (TF-IDF Model): \~85% (on limited 105 labeled samples)
* BERT Model: Better contextual performance (subject to labeled data size)

---

## ğŸ’¡ Future Improvements

* Increase labeled data (active learning)
* Fine-tune larger transformer models
* Add Streamlit or Flask-based UI
* Add confidence scores & explainability (e.g., SHAP)

---

## ğŸ‘¨â€ğŸ’» Author

**Vivek Nagar**
*MCA Graduate | Aspiring Machine Learning Engineer*
ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/vivek-nagar)

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

